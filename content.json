[{"title":"notes for hotkeys","date":"2017-06-09T06:51:58.000Z","path":"2017/06/09/notes-for-hotkeys/","text":"Python批量注释和解注释:control+/ 批量缩进: tab and tab+shift MatlabTex studio批量注释和解注释:command+T + command+U","tags":[{"name":"hotkeys","slug":"hotkeys","permalink":"http://yoursite.com/tags/hotkeys/"}]},{"title":"Keras-switch-backend","date":"2017-06-07T10:35:53.000Z","path":"2017/06/07/Keras-switch-backend/","text":"Switching from one backend to anotherIf you have run Keras at least once, you will find the Keras configuration file at: 1$HOME/.keras/keras.json If it isn’t there, you can create it. NOTE for Windows Users: Please change $HOME with %USERPROFILE%. The default configuration file looks like this: 123456&#123;&quot;image_data_format&quot;: &quot;channels_last&quot;,&quot;epsilon&quot;: 1e-07,&quot;floatx&quot;: &quot;float32&quot;,&quot;backend&quot;: &quot;tensorflow&quot;&#125; Simply change the field backend to either “theano” or “tensorflow”, and Keras will use the new configuration next time you run any Keras code. You can also define the environment variable KERAS_BACKEND and this will override what is defined in your config file :12KERAS_BACKEND=tensorflow python -c &quot;from keras import backend&quot;Using TensorFlow backend.","tags":[]},{"title":"GAN-learning-1","date":"2017-06-07T07:58:59.000Z","path":"2017/06/07/GAN-learning-1/","text":"","tags":[]},{"title":"Useful tools","date":"2017-06-07T07:56:32.000Z","path":"2017/06/07/Useful-tools/","text":"","tags":[]},{"title":"","date":"2017-05-13T10:15:15.000Z","path":"2017/05/13/Methodology/","text":"Methodology","tags":[]},{"title":"Some Basic knowledge for programming ","date":"2017-04-08T02:02:27.000Z","path":"2017/04/08/Some-Basic-knowledge-for-programming/","text":"virtual function在某基类中声明为 virtual 并在一个或多个派生类中被重新定义的成员函数，用法格式为：virtual 函数返回类型 函数名（参数表） {函数体}；实现多态性，通过指向派生类的基类指针或引用，访问派生类中同名覆盖成员函数 multiple threaddeadlock and starvationUDPUDP is Connectionless Protocal TCPTo establish a connection, TCP uses a three-way handshake. Before a client attempts to connect with a server, the server must first bind to and listen at a port to open it up for connections: this is called a passive open. Once the passive open is established, a client may initiate an active open. To establish a connection, the three-way (or 3-step) handshake occurs: SYN: The active open is performed by the client sending a SYN to the server. The client sets the segment’s sequence number to a random value A.SYN-ACK: In response, the server replies with a SYN-ACK. The acknowledgment number is set to one more than the received sequence number i.e. A+1, and the sequence number that the server chooses for the packet is another random number, B.ACK: Finally, the client sends an ACK back to the server. The sequence number is set to the received acknowledgement value i.e. A+1, and the acknowledgement number is set to one more than the received sequence number i.e. B+1.At this point, both the client and server have received an acknowledgment of the connection. The steps 1, 2 establish the connection parameter (sequence number) for one direction and it is acknowledged. The steps 2, 3 establish the connection parameter (sequence number) for the other direction and it is acknowledged. With these, a full-duplex communication is established. some tricks What is the difference between using ++i and i++? ++i will increment the value of i, and then return the incremented value. 123 i = 1; j = ++i;(i is 2, j is 2) i++ will increment the value of i, but return the original value that i held before being incremented. 123i = 1;j = i++;(i is 2, j is 1)","tags":[]},{"title":"Leetcode","date":"2017-04-07T11:17:13.000Z","path":"2017/04/07/Leetcode/","text":"Minimum Depth of Binary TreeGiven a binary tree, find its minimum depth.The minimum depth is the number of nodes along the shortest path from the root node down to the nearest leaf node. java: 1234567891011121314151617181920212223/** * Definition for binary tree * public class TreeNode &#123; * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) &#123; val = x; &#125; * &#125; */public class Solution &#123; public int run(TreeNode root) &#123; if (root == null)&#123; return 0; &#125; else if (root.left == null)&#123; return run(root.right) + 1; &#125; else if (root.right == null)&#123; return run(root.left) + 1; &#125; else &#123; return Math.min(run(root.left), run(root.right))+1; &#125; &#125;&#125; c++ 123456789101112131415161718class Solution &#123;public: int run(TreeNode *root) &#123; if(root == nullptr) &#123; return 0; &#125; else if (root-&gt;left == nullptr )&#123; return run(root -&gt;right) + 1; &#125; else if (root-&gt; right == nullptr)&#123; return run(root -&gt;left) +1; &#125; else&#123; return 1 + min(run(root-&gt;left),run(root-&gt;right)); &#125; &#125;&#125;; Reverse Polish NotationEvaluate the value of an arithmetic expression in Reverse Polish Notation.Valid operators are+,-,*,/. Each operand may be an integer or another expression.Some examples: 12[&quot;2&quot;, &quot;1&quot;, &quot;+&quot;, &quot;3&quot;, &quot;*&quot;] -&gt; ((2 + 1) * 3) -&gt; 9[&quot;4&quot;, &quot;13&quot;, &quot;5&quot;, &quot;/&quot;, &quot;+&quot;] -&gt; (4 + (13 / 5)) -&gt; 6 max-points-on-a-lineGiven n points on a 2D plane, find the maximum number of points that lie on the same straight line. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677#include &lt;vector&gt;#include &lt;iostream&gt; using namespace std; /** * Definition for a point. * struct Point &#123; * int x; * int y; * Point() : x(0), y(0) &#123;&#125; * Point(int a, int b) : x(a), y(b) &#123;&#125; * &#125;; */class Solution &#123;public: int maxPoints(vector&lt;Point&gt; &amp;points) &#123; int size = points.size(); if( size == 0)&#123; return 0; &#125; else if (size == 1)&#123; return 1; &#125; else &#123; int result = 0; for (int i = 0; i &lt; size; ++i)&#123; int curmax = 1; int same = 0; int verticle = 1; map &lt; double, int &gt; m; for (int j = 0; j &lt; size; ++j)&#123; if(i == j) continue; int dx = points[i].x - points[j].x; int dy = points[i].y - points[j].y; if(dx == 0)&#123; if (dy == 0) &#123;same ++;&#125; else&#123; verticle ++; curmax = max( curmax, verticle); &#125; &#125;else&#123; double k = (1.0*dy)/dx; if(m[k] == 0)&#123; m[k] = 2; &#125;else&#123; ++m[k]; &#125; curmax = max(m[k],curmax); &#125; &#125; result = max(result, curmax + same); &#125; return result; &#125; &#125;&#125;; sort-listSort a linked list in O(n log n) time using constant space complexity. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode(int x) : val(x), next(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: ListNode *merge(ListNode * left, ListNode * right)&#123; ListNode tmp(0); ListNode *p = &amp;tmp; while (left &amp;&amp; right)&#123; if (left -&gt; val &lt; right -&gt; val)&#123; p -&gt; next = left; left = left -&gt; next; &#125; else&#123; p -&gt; next = right; right = right -&gt; next; &#125; p = p -&gt;next; &#125; if(left)&#123; p -&gt; next = left; &#125; if(right)&#123; p -&gt; next = right; &#125; return tmp.next; &#125; ListNode *sortList(ListNode *head) &#123; if(!head || !head-&gt;next)&#123; return head; &#125; ListNode *p = head, *q = head-&gt;next; while(q &amp;&amp; q-&gt;next)&#123; p = p-&gt;next; q = q-&gt;next-&gt;next; &#125; ListNode * right = sortList( p -&gt;next); p -&gt;next = NULL; ListNode * left = sortList(head); return merge(left, right); &#125;&#125;; two-sumGiven an array of integers, find two numbers such that they add up to a specific target number.The function twoSum should return indices of the two numbers such that they add up to the target, where index1 must be less than index2. Please note that your returned answers (both index1 and index2) are not zero-based.You may assume that each input would have exactly one solution.Input: numbers={2, 7, 11, 15}, target=9Output: index1=1, index2=2 123456789101112131415161718192021class Solution &#123;public: vector&lt;int&gt; twoSum(vector&lt;int&gt; &amp;numbers, int target) &#123; vector &lt;int&gt; ans; int index1 = 0; int index2 = 0; for (int i = 0; i &lt; numbers.size() - 1; ++i)&#123; int tmp = target - numbers[i]; for(int j = i+1; j &lt;numbers.size(); ++j )&#123; if (tmp == numbers[j])&#123; ans.push_back(i+1); ans.push_back(j+1); &#125; &#125; &#125; return ans; &#125;&#125;; using hash unordered_map123456789101112131415161718192021222324252627282930313233343536373839404142#include &lt;unordered_map&gt;using namespace std;class Solution &#123;public: vector&lt;int&gt; twoSum(vector&lt;int&gt; &amp;numbers, int target) &#123; unordered_map &lt;int, int&gt; hash; vector &lt;int&gt; res; for (int i = 0; i &lt; numbers.size(); ++i)&#123; hash[numbers[i]] = i; &#125; for (int i = 0; i &lt; numbers.size(); ++i)&#123; int tmp = target - numbers[i]; if(hash.find(tmp)!= hash.end() &amp;&amp; hash[tmp] &gt; i)&#123; res.push_back(i+1); res.push_back(hash[tmp] + 1); &#125; &#125; return res; /* vector &lt;int&gt; ans; int index1 = 0; int index2 = 0; for (int i = 0; i &lt; numbers.size() - 1; ++i)&#123; int tmp = target - numbers[i]; for(int j = i+1; j &lt;numbers.size(); ++j )&#123; if (tmp == numbers[j])&#123; ans.push_back(i+1); ans.push_back(j+1); &#125; &#125; &#125; return ans;*/ &#125;&#125;; balanced-binary-treeGiven a binary tree, determine if it is height-balanced.For this problem, a height-balanced binary tree is defined as a binary tree in which the depth of the two subtrees of every node never differ by more than 1. 12345678910111213141516171819202122232425262728293031323334/** * Definition for binary tree * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: int getDepth(TreeNode * root)&#123; if (root == NULL) return 0; if (root -&gt; left == NULL) return 1 + getDepth(root -&gt;right); if (root -&gt; right == NULL) return 1 + getDepth(root -&gt;left); return 1 + max(getDepth(root-&gt; left), getDepth(root-&gt; right)); &#125; bool isBalanced(TreeNode *root) &#123; if (root == NULL) return true; int left = getDepth(root -&gt; left); int right = getDepth(root -&gt; right); if (abs(left - right) &gt; 1 ) return false; return (isBalanced(root -&gt; left) &amp;&amp; isBalanced(root -&gt; right)); &#125;&#125;; binary-preorder-traversalGiven a binary tree, return the preorder traversal of its nodes’ values.For example:Given binary tree{1,#,2,3}, 123451 \\ 2 /3 return[1,2,3].Note: Recursive solution is trivial, could you do it iteratively? ###Recursive 1234567891011121314151617181920212223242526272829/** * Definition for binary tree * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: vector&lt;int&gt; preorderTraversal(TreeNode *root) &#123; vector &lt;int&gt; result; if (root == NULL) return result; helper(root,result); return result; &#125; private: void helper(TreeNode * root, vector &lt;int&gt; &amp;vec)&#123; if (root == NULL) return; vec.push_back(root -&gt; val); helper(root -&gt; left, vec); helper(root -&gt; right, vec); &#125;&#125;; iterative12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/** * Definition for binary tree * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: vector&lt;int&gt; preorderTraversal(TreeNode *root) &#123; vector &lt;int&gt; result; stack &lt;TreeNode *&gt; st; if (root == NULL) return result; st.push(root); while(!st.empty())&#123; TreeNode * current = st.top(); st.pop(); if (current -&gt; right != NULL) st.push(current-&gt;right); if (current -&gt; left != NULL) st.push(current-&gt;left); result.push_back(current -&gt; val); &#125; //helper(root,result); return result; &#125; private: void helper(TreeNode * root, vector &lt;int&gt; &amp;vec)&#123; if (root == NULL) return; vec.push_back(root -&gt; val); helper(root -&gt; left, vec); helper(root -&gt; right, vec); &#125;&#125;; string to integer atoiImplement atoi to convert a string to an integer.Hint: Carefully consider all possible input cases. If you want a challenge, please do not see below and ask yourself what are the possible input cases.Notes: It is intended for this problem to be specified vaguely (ie, no given input specs). You are responsible to gather all the input requirements up front.spoilers alert… click to show requirements for atoi.Requirements for atoi:The function first discards as many whitespace characters as necessary until the first non-whitespace character is found. Then, starting from this character, takes an optional initial plus or minus sign followed by as many numerical digits as possible, and interprets them as a numerical value.The string can contain additional characters after those that form the integral number, which are ignored and have no effect on the behavior of this function.If the first sequence of non-whitespace characters in str is not a valid integral number, or if no such sequence exists because either str is empty or it contains only whitespace characters, no conversion is performed.If no valid conversion could be performed, a zero value is returned. If the correct value is out of the range of representable values, INT_MAX (2147483647) or INT_MIN (-2147483648) is returned. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546class Solution &#123;public: int atoi(const char *str) &#123; long long res = 0; if (str == NULL)&#123; return res; &#125; int len = strlen(str); int i = 0; bool neg = false; while (str[i] == ' '|| str[i] == '0')&#123; ++i; &#125; if (str[i] == '-')&#123; neg = true; ++i; &#125; else if (str[i] == '+')&#123; neg = false; ++i; &#125; for (;i &lt; len;++i)&#123; char ch = str[i]; if (ch &gt;='0' &amp;&amp; ch &lt;='9')&#123; res = res*10 + ch - '0'; if (res &gt; INT_MAX)&#123; return neg? INT_MIN:INT_MAX; &#125; &#125;else&#123; if (neg) return -res; return res; &#125; &#125; if (neg) return -res; return res; &#125;&#125;; merge two sorted listsMerge two sorted linked lists and return it as a new list. The new list should be made by splicing together the nodes of the first two lists. 123456789101112131415161718192021222324252627282930313233343536373839/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode(int x) : val(x), next(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: ListNode *mergeTwoLists(ListNode *l1, ListNode *l2) &#123; if (l1 == NULL) return l2; if (l2 == NULL) return l1; ListNode * dummy = new ListNode(0); ListNode * p = dummy; while(l1!=NULL &amp;&amp; l2!=NULL)&#123; if (l1-&gt;val &lt; l2-&gt;val)&#123; p-&gt;next = l1; l1 = l1-&gt;next; &#125;else &#123; p -&gt; next = l2; l2 = l2 -&gt; next; &#125; p = p -&gt;next; &#125; if(l1!= NULL)&#123; p -&gt; next = l1; &#125; if(l2!= NULL)&#123; p -&gt; next = l2; &#125; return dummy -&gt; next; &#125;&#125;; ## 12","tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"http://yoursite.com/tags/Leetcode/"}]},{"title":"Glossary of Conformal Geometry Related","date":"2017-03-31T07:58:13.000Z","path":"2017/03/31/Glossary-of-Conformal-Geometry-Related/","text":"Glossarymanifold(流形)流形是局部具有欧几里得空间性质的空间，流形在数学中用于描述几何形体，物理上，经典力学的相空间和构造广义相对论的时空模型的四维伪黎曼流形都是流形的实例。 homeomorphism(同胚)在拓扑学中，两个流形，如果可以通过弯曲、延展、剪切(只要最终完全沿着当初剪开的缝隙再重新粘贴起来)等操作把其中一个变为另一个，则认为两者是同胚的。如：圆和正方形是同胚的，而球面和环面就不是同胚的。 同胚映射：设X和Y是拓扑空间。如果f：X→Y是一一映射，并且f及其逆g：Y→X都是连续的，则称f是一个同胚映射，或称拓扑变换，或简称同胚。 同胚：当存在X到Y的同胚映射时，称X与Y同胚。记作X≌Y。 diffeomorphism(微分同胚)对维度小于3的流形，可证明同胚的流形必为微分同胚；换言之，此时流形上的拓扑结构确定了微分结构。 biholomorphiccurl（旋度）div（散度）Half-edge data structureDual","tags":[{"name":"Conformal Geometry","slug":"Conformal-Geometry","permalink":"http://yoursite.com/tags/Conformal-Geometry/"}]},{"title":"What is conformal or holomorphic","date":"2017-03-31T00:37:37.000Z","path":"2017/03/31/What-is-conformal-or-holomorphic/","text":"Beltrami equation$\\frac{\\partial{}}{\\partial{z}} := \\frac{1}{2}()$","tags":[{"name":"Conformal Geometry","slug":"Conformal-Geometry","permalink":"http://yoursite.com/tags/Conformal-Geometry/"}]},{"title":"Notes for write Markdown File","date":"2017-03-29T04:28:51.000Z","path":"2017/03/29/Notes-for-write-Markdown-File/","text":"Notes No space after ``` to use.","tags":[{"name":"Blog","slug":"Blog","permalink":"http://yoursite.com/tags/Blog/"}]},{"title":"Using HEXO to write blogs","date":"2017-03-28T15:34:59.000Z","path":"2017/03/28/Using-HEXO-to-write-blogs/","text":"Hexo is a fast, simple and powerful blog framework. And we can use Markdown to write it, so it is very efficient. I migrate the old blogs to this theme. Install HexoUsing npm to install it. 1npm install -g hexo-cli Set up for first using itMake a directory for blog: 1mkdir ~/blog Init for Hexo: 1hexo init Update _config.yml file in work directory for github info: 12345deploy: type: git repo: &#123;your github repo url&#125; branch: master message: &quot;Site updated: &#123;&#123; now(&apos;YYYY-MM-DD HH:mm:ss&apos;) &#125;&#125;&quot; Then run the following command to take effect: 1npm install hexo-deployer-git --save Install ThemeRef: https://github.com/litten/hexo-theme-yilia 1git clone https://github.com/litten/hexo-theme-yilia.git themes/yilia Modify _config.yml in root dir: 1theme: yilia Next, how to write blogs. Write a blogCreate a blog: 1hexo new &quot;Post Name&quot; It will create a .md file in blog/source/_post directory, edit and write it. Clean Folder: 1hexo clean Generate static page to public folder: 1hexo generate Deploy to github: 1hexo deploy ReferenceLinks: https://hexo.io/docs/","tags":[{"name":"Blog","slug":"Blog","permalink":"http://yoursite.com/tags/Blog/"}]},{"title":"Install Tensorflow from Source Code","date":"2016-08-19T03:55:45.000Z","path":"2016/08/19/Install-Tensorflow-from-Source-Code/","text":"Install bazelInstall java jdkRequired Java version: Java JDK 8 or later (JDK 7 is still supported but deprecated). In centos we can simply install this by command:1yum install -y java-1.8.0-openjdk set JAVA_HOME environment variables in .bashrc: 1export JAVA_HOME=/usr/lib/jvm/java-openjdk Download bazel source codeDownload from github and compile: 123git clone https://github.com/bazelbuild/bazel.gitcd bazel./compile.sh Set bazel to PATHADD bazel-bin/src/bazel to .bashrc In my server as: 1export PATH=$PATH:/root/bazel/output Now, we have install the bazel in centos. If you use Ubuntu OS, you can install it form apt repository. In this blog, I will not tell the detailed, which you can reference the link: 1http://bazel.io/docs/install.html#compiling-from-source Install TensorflowDownload source codeClone the tensorflow from github: 1git clone https://github.com/tensorflow/tensorflow Configure for installation12cd tensorflow/./configure Then, it will tell you which environment to set. such as: 1234567891011121314151617181920212223242526Please specify the location of python. [Default is /usr/local/anaconda2/bin/python]: Do you wish to build TensorFlow with Google Cloud Platform support? [y/N] nNo Google Cloud Platform support will be enabled for TensorFlowFound possible Python library paths: /usr/local/anaconda2/lib/python2.7/site-packagesPlease input the desired Python library path to use. Default is [/usr/local/anaconda2/lib/python2.7/site-packages]/usr/local/anaconda2/lib/python2.7/site-packagesDo you wish to build TensorFlow with GPU support? [y/N] yGPU support will be enabled for TensorFlowPlease specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: Please specify the Cuda SDK version you want to use, e.g. 7.0. [Leave empty to use system default]: Please specify the location where CUDA toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: Please specify the Cudnn version you want to use. [Leave empty to use system default]: Please specify the location where cuDNN library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: Please specify a list of comma-separated Cuda compute capabilities you want to build with.You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.Please note that each additional compute capability significantly increases your build time and binary size.[Default is: &quot;3.5,5.2&quot;]: Setting up Cuda includeSetting up Cuda lib64Setting up Cuda binSetting up Cuda nvvmSetting up CUPTI includeSetting up CUPTI lib64Configuration finished Create the pip package and installWhen building from source, you will still build a pip package and install that. 1234# To build with GPU support:bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_packagebazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkgpip install /tmp/tensorflow_pkg/tensorflow-0.10.0rc0-py2-none-any.whl Setting up TensorFlow for DevelopmentIf you’re working on TensorFlow itself, it is useful to be able to test your changes in an interactive python shell without having to reinstall TensorFlow. To set up TensorFlow such that all files are linked (instead of copied) from the system directories, run the following commands inside the TensorFlow root directory: 123456789bazel build -c opt //tensorflow/tools/pip_package:build_pip_package# To build with GPU support:bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_packagemkdir _python_buildcd _python_buildln -s ../bazel-bin/tensorflow/tools/pip_package/build_pip_package.runfiles/org_tensorflow/* .ln -s ../tensorflow/tools/pip_package/* . Such as change the version from 0.10.0 to 0.11.0 filetensorflow/tools/pip_package/setup.py: 1_VERSION = '0.11.0rc0' Then, do the following:1python setup.py develop Now, we can build our develop tensorflow: 12bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkgpip install /tmp/tensorflow_pkg/tensorflow-0.11.0rc0-py2-none-any.whl Verify the installation12345678910111213[root@node-4 site-packages]# pip show tensorflowMetadata-Version: 2.0Name: tensorflowVersion: 0.11.0rc0Summary: TensorFlow helps the tensors flowHome-page: http://tensorflow.org/Author: Google Inc.Author-email: opensource@google.comInstaller: pipLicense: Apache 2.0Location: /usr/local/anaconda2/lib/python2.7/site-packagesRequires: numpy, mock, protobuf, wheel, six We can find the version changed from the 0.10.0tc0 to 0.11.0rc0. Referenceofficial link:this.","tags":[{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://yoursite.com/tags/Deep-Learning/"}]},{"title":"Play distributed Tensorflow with GPU accelerated","date":"2016-04-25T03:55:21.000Z","path":"2016/04/25/Play-distributed-Tensorflow-with-GPU-accelerated/","text":"IntroductionTensorFlow™ is an open source software library for numerical computation using data flow graphs. TensorFlow is for everyone. It’s for students, researchers, hobbyists, hackers, engineers, developers, inventors and innovators and is being open sourced under the Apache 2.0 open source license. Distributed versionIn April 13,2006.Distributed version of Tensorflow was published. Announcing TensorFlow 0.8 – now with distributed computing support! This blog is also reposted by Jeff Dean in G+ who is the Google Senior Fellow in the Systems Infrastructure Group. InstallationI try the distributed version in 3 virtual machines on OpenStack platform which is a famous open source cloud OS. Environment 1 master node 2 worker nodes Configuration:4GB RAM, 2 VCPU, 40.0GB Disk Operating System:ubuntu-14.04-server-cloudimg-amd64 Python version:2.7 Tensorflow version:r0.8 vCPU only. Install pip Download get-pip.py file. 1wget https://bootstrap.pypa.io/get-pip.py Install the pip behind a proxy 1python get-pip.py --proxy=&quot;[user:passwd@]proxy.server:port&quot; Upgrading pip 1pip install -U pip Install Tensorflow by pip Ubuntu/Linux 64-bit, GPU enabled. Requires CUDA toolkit 7.5 and CuDNN v4. 1sudo pip install --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.8.0-cp27-none-linux_x86_64.whl Ubuntu/Linux 64-bit, CPU only: 1sudo pip install --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.8.0-cp27-none-linux_x86_64.whl Demo of Distributed TensorFlowNow we have setup the preparation for a demo. This demo is according to the tutorial of Tensorflow. https://www.tensorflow.org/versions/r0.8/how_tos/distributed/index.html Describe of a clusterA TensorFlow “cluster” is a set of “tasks” that participate in the distributed execution of a TensorFlow graph. Each task is associated with a TensorFlow “server”, which contains a “master” that can be used to create sessions, and a “worker” that executes operations in the graph. A cluster can also be divided into one or more “jobs”, where each job contains one or more tasks. Two important instrucionsCreate a tf.train.ClusterSpec that describes all of the tasks in the cluster. This should be the same for each task. Create a tf.train.Server, passing the tf.train.ClusterSpec to the constructor, and identifying the local task with a job name and task index. Specific a clusterWe define 2 worker node and 1 parameter server node as the following: 123cluster = tf.train.ClusterSpec(&#123;&quot;worker&quot;: [&quot;tensorflow-worker0:2222&quot;, &quot;tensorflow-worker1:2222&quot;], &quot;ps&quot;: [&quot;tensorflow-master0:2222&quot;]&#125;) master node Write ps.py as the following for parameter server: 123456789import tensorflow as tfcluster = tf.train.ClusterSpec(&#123;&quot;worker&quot;: [&quot;tensorflow-worker0:2222&quot;, &quot;tensorflow-worker1:2222&quot;], &quot;ps&quot;: [&quot;tensorflow-master0:2222&quot;]&#125;)server = tf.train.Server(cluster, job_name=&quot;ps&quot;, task_index=0)server.join() Run the script 1234# python ps.py I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job ps -&gt; &#123;localhost:2222&#125;I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job worker -&gt; &#123;tensorflow-worker0:2222, tensorflow-worker1:2222&#125;I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:202] Started server with target: grpc://localhost:2222 It will listen on the 2222 port of master0 server. worker nodeIn the two worker nodes, do the following steps: Write worker0.py as the following: 123456789import tensorflow as tfcluster = tf.train.ClusterSpec(&#123;&quot;worker&quot;: [&quot;tensorflow-worker0:2222&quot;, &quot;tensorflow-worker1:2222&quot;], &quot;ps&quot;: [&quot;tensorflow-master0:2222&quot;]&#125;)server = tf.train.Server(cluster, job_name=&quot;worker&quot;, task_index=0)server.join() Run the script 1234# python worker0.py I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job ps -&gt; &#123;tensorflow-master0:2222&#125;I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job worker -&gt; &#123;localhost:2222, tensorflow-worker1:2222&#125;I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:202] Started server with target: grpc://localhost:2222 It will listen on the 2222 port of worker0 server. Write worker1.py as the following: 123456789import tensorflow as tfcluster = tf.train.ClusterSpec(&#123;&quot;worker&quot;: [&quot;tensorflow-worker0:2222&quot;, &quot;tensorflow-worker1:2222&quot;], &quot;ps&quot;: [&quot;tensorflow-master0:2222&quot;]&#125;)server = tf.train.Server(cluster, job_name=&quot;worker&quot;, task_index=1)server.join() Run the script 1234# python worker1.py I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job ps -&gt; &#123;tensorflow-master0:2222&#125;I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job worker -&gt; &#123;tensorflow-worker0:2222, localhost:2222&#125;I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:202] Started server with target: grpc://localhost:2222 It will listen on the 2222 port of worker1 server. Test Job Task The test job script is the following: 123456789101112131415161718import tensorflow as tfwith tf.device(&quot;/job:ps/task:0&quot;): weights0 = tf.Variable(tf.random_normal(shape=[1024, 512])) bias0 = tf.Variable(tf.zeros(shape=[512]))with tf.device(&quot;/job:worker/task:1&quot;): inputs = tf.random_normal(shape=[10, 1024]) l0 = tf.nn.relu(tf.matmul(inputs, weights0) + bias0) l1 = tf.nn.relu(tf.matmul(l0, tf.transpose(weights0))) loss = tf.nn.l2_loss(l1-inputs) train_op = tf.train.AdamOptimizer().minimize(loss)with tf.Session(&quot;grpc://tensorflow-master0:2222&quot;) as sess: for _ in range(1000): sess.run(tf.initialize_all_variables()) _, l = sess.run([train_op, loss]) print l ps node is to generate normal random variables. worker node is to training the model. Results When run the script, it will generate data in device: &quot;/job:ps/task:0&quot; and train the data in device=/job:worker/task:1 as the following: 123456789101112131415161718192021222324252627282930313233# python job.py name: &quot;Adam&quot;op: &quot;NoOp&quot;input: &quot;^Adam/update_Variable/ApplyAdam&quot;input: &quot;^Adam/update_Variable_1/ApplyAdam&quot;input: &quot;^Adam/Assign&quot;input: &quot;^Adam/Assign_1&quot;device: &quot;/job:ps/task:0&quot; Tensor(&quot;L2Loss:0&quot;, shape=(), dtype=float32, device=/job:worker/task:1)name: &quot;Adam&quot;op: &quot;NoOp&quot;input: &quot;^Adam/update_Variable/ApplyAdam&quot;input: &quot;^Adam/update_Variable_1/ApplyAdam&quot;input: &quot;^Adam/Assign&quot;input: &quot;^Adam/Assign_1&quot;device: &quot;/job:ps/task:0&quot; Tensor(&quot;L2Loss:0&quot;, shape=(), dtype=float32, device=/job:worker/task:1)name: &quot;Adam&quot;op: &quot;NoOp&quot;input: &quot;^Adam/update_Variable/ApplyAdam&quot;input: &quot;^Adam/update_Variable_1/ApplyAdam&quot;input: &quot;^Adam/Assign&quot;input: &quot;^Adam/Assign_1&quot;device: &quot;/job:ps/task:0&quot; Tensor(&quot;L2Loss:0&quot;, shape=(), dtype=float32, device=/job:worker/task:1)name: &quot;Adam&quot;op: &quot;NoOp&quot;input: &quot;^Adam/update_Variable/ApplyAdam&quot;input: &quot;^Adam/update_Variable_1/ApplyAdam&quot;input: &quot;^Adam/Assign&quot;input: &quot;^Adam/Assign_1&quot;device: &quot;/job:ps/task:0&quot;... Further WorkThis blog is only a try of distributed tensorflow, there are many works need to do. such as how to combined working with GPU, how to benchmark and so on. Referencehttps://www.tensorflow.org https://github.com/tensorflow/tensorflow http://googleresearch.blogspot.com/2016/04/announcing-tensorflow-08-now-with.html","tags":[{"name":"Deep Learning","slug":"Deep-Learning","permalink":"http://yoursite.com/tags/Deep-Learning/"}]},{"title":"Play Tricircle with virtualbox","date":"2016-03-07T03:54:38.000Z","path":"2016/03/07/Play-Tricircle-with-virtualbox/","text":"Playing Tricircle with Virtualbox1 Preparation1 server with Linux kernel (demo is Ubuntu 14.04 LTS) 2 Install softwares2.1 Install virtualboxFollow the steps in virtualbox downloads First, Add the following line to your /etc/apt/sources.list:1deb http://download.virtualbox.org/virtualbox/debian trusty contrib According to your distribution, replace ‘vivid’ by ‘utopic’, ‘trusty’, ‘raring’, ‘quantal’, ‘precise’, ‘lucid’, ‘jessie’, ‘wheezy’, or ‘squeeze’. Then, add The Oracle public key for apt-secure:1wget -q https://www.virtualbox.org/download/oracle_vbox.asc -O- | sudo apt-key add - Next, install with apt-get method:12sudo apt-get updatesudo apt-get install virtualbox-5.0 2.2 Connect to the virtualbox with x11First, copy your public key to the ~/authorized_keysThen, connect with -X command1ssh -X root@HostIP Next, input the virtualbox to start install virtual machine1virtualbox Then you can see the virtualbox graph interface: 3 Install Virtual MachinesFor playing Tricircle, we need to install 3 nodes for devstack.One for the Top OpenStack, Two for cross pod bottom OpenStacks. 3.1 Configuration of VMsThe most important is to set up networks for useIn order to make the VMs with multiple VLAN networks, then add 2 network devices for bridge use. eth0The eth0 is the default network with NAT methods. eth1The eth1 is the VLAN external network,and using bridge method, in my environment, I attached to the eth1. [attention] The Promiscuous Mode must to set “Allow All”.And be in use after reboot.Otherwise, The Ping test with VLAN tag from Node1 to Node2 will be blocked. eth2The same setting as the above, the Promiscuous Mode must be set to “Allow All”. And be in use after reboot. 3.2 Installation the VMsDownload a ios for installationThere are many mirror sites in the world. I download a ubuntu-14.04-LTS in the Ali-OSM(Alibaba Open Source Mirror Site). Because it’s very fast in China. Install the Operating SystemFollow the steps while installing, because it’s easy, so it will be ignored.After installation, you will see the console like this: 3.3 Running in the backgroudAfter installation of the VMs, we can login from SSH. So we need to let’s these VMs running in the background.And so when we close the VMs, we need to choose the option: 4 Playing tricircle with devstackThe detailed methods can be seen in the OpenStack/Tricircle. 4.1 In Top OpenStackConfigure the networkInstall the openvswitch for creating bridges. 1apt-get install openvswitch-switch Create the stack user1234adduser stack``` #### Give the stack user sudo privileges: apt-get install sudo -yecho “stack ALL=(ALL) NOPASSWD: ALL” &gt;&gt; /etc/sudoers12#### Download the devstack sudo apt-get install git -ygit clone https://git.openstack.org/openstack-dev/devstackcd devstack12345#### Configure the local.confChange the local.conf to fit your environment.The example is in the Tricircle Project. such as [local.conf.sample](https://github.com/openstack/tricircle/blob/master/devstack/local.conf.sample).#### Install the devstack with Tricircle project ./stack.sh123456After installing the devstack with tricircle, the next step is verifying the installation.#### Verifying the installationBefore verifying, It should create the client environment variables to import, such as :admin-openrc.sh export OS_PROJECT_DOMAIN_ID=defaultexport OS_USER_DOMAIN_ID=defaultexport OS_PROJECT_NAME=adminexport OS_TENANT_NAME=adminexport OS_USERNAME=adminexport OS_PASSWORD=password #change password as you set in your own environmentexport OS_AUTH_URL=http://127.0.0.1:5000export OS_IDENTITY_API_VERSION=3 #It’s very important to set region name to the top openstack, because tricircle has different API urls.export OS_REGION_NAME=RegionOne123Modify the verify install scripts as your own environment.And run: cd tricircle/devstackchmod +x verify_top_install.sh./verify_top_install.sh 2&gt;&amp;1 | tee logs12345678910111213141516171819202122It will save the outputs in the logs, you can check if it&apos;s installed correct.I pasted one copy in my environments as [this](https://docs.google.com/document/d/1NQvRJo5bnnvYMUCLar-rRRm65KHOMmNpZasQlZCBgXs/edit?usp=sharing).### 4.2 Cross pods OpenStack#### InstallingFirst, in the node1 install the tricircle, and then in the node2 install the tricircle.As the above:&lt;li&gt; Modify the networks;&lt;/li&gt;&lt;li&gt; Create the stack user;&lt;/li&gt;&lt;li&gt; Install git;&lt;/li&gt;&lt;li&gt; Download the devstack;&lt;/li&gt;&lt;li&gt; Modify the local.conf;&lt;/li&gt;&lt;li&gt; Install the devstack with tricircle;&lt;/li&gt;&lt;br&gt;#### Verifying the tricircleBefore verifying, It should create the client environment variables to import, such as :admin-openrc.sh export OS_PROJECT_DOMAIN_ID=defaultexport OS_USER_DOMAIN_ID=defaultexport OS_PROJECT_NAME=adminexport OS_TENANT_NAME=adminexport OS_USERNAME=adminexport OS_PASSWORD=password #change password as you set in your own environmentexport OS_AUTH_URL=http://127.0.0.1:5000export OS_IDENTITY_API_VERSION=3 #It’s very important to set region name to the top openstack, because tricircle has different API urls.export OS_REGION_NAME=RegionOne123Modify the verify install scripts as your own environment.And run: cd tricircle/devstackchmod +x verify_top_install.sh./verify_cross_pod_install.sh 2&gt;&amp;1 | tee logs123456789One copy logs like [this](https://docs.google.com/document/d/1srGuk2XY8VIbmhGKEVBVbQ_MW5sUByGBDZcJVVS_2Cg/edit?usp=sharing).#### Ping testUsing the VNC to login the instances in Node1 and Node2.And Ping with each other.VM1: IP 10.0.1.3/24 ping -c 4 10.0.2.31234![vm1](http://img.blog.csdn.net/20160308143200217)VM2: IP 10.0.2.3/24 ping -c 4 10.0.1.3``` So the cross pod networking has been verified.","tags":[{"name":"Cloud Computing","slug":"Cloud-Computing","permalink":"http://yoursite.com/tags/Cloud-Computing/"}]},{"title":"SODA git and spark","date":"2015-11-15T03:48:15.000Z","path":"2015/11/15/SODA-git-and-spark/","text":"SODA比赛(Shanghai Open Data Apps)一共有超过400个参赛选手，对于比赛大数据的处理，需要强力的技术支持，我们为进入复赛的参赛队伍免费提供了两个数据平台，并分别导入大赛数据，供选手使用。它们分别是： Spark Vertica 本文介绍 Gitlab 环境的部署过程、使用方法以及如何通过后台自动调用Spark集群进行数据计算。 SODA瓶之Spark环境请戳 SODA瓶之Ganglia监控 SODA瓶之Vertica on OpenStack Gitlab介绍GitlabGitLab，是一个利用 Ruby on Rails 开发的开源应用程序，实现一个自托管的Git项目仓库，可通过Web界面进行访问公开的或者私人项目。 它拥有与GitHub类似的功能，能够浏览源代码，管理缺陷和注释。可以管理团队对仓库的访问，它非常易于浏览提交过的版本并提供一个文件历史库。团队成员可以利用内置的简单聊天程序（Wall）进行交流。它还提供一个代码片段收集功能可以轻松实现代码复用，便于日后有需要的时候进行查找。 比赛代码托管平台搭建本次比赛的所有代码考虑到隐私性、安全性等因素，采用了完全由OMNILab搭建的Gitlab私有代码仓库。参赛选手可以将编写好的代码上传至比赛专用的Gitlab，然后可以通过Gitlab调用后台为比赛专门准备的Spark计算集群，进行数据计算。 具体代码仓库搭建过程如下： gitlab预装环境搭建安装包括ssh、email等服务 12sudo apt-get install curl openssh-server ca-certificates postfixgitlab仓库搭建以及配置 增加gitlab的package并且安装： 12curl https://packages.gitlab.com/install/repositories/gitlab/gitlab-ce/script.deb.sh | sudo bashsudo apt-get install gitlab-ce 配置并启动gitlab服务12curl -LJO https://packages.gitlab.com/gitlab/gitlab-ce/packages/ubuntu/trusty/gitlab-ce-XXX.deb/downloaddpkg -i gitlab-ce-XXX.deb 批量创建用户名、密码首先，通过正则表达式匹配，将KESCI提供的邮箱中的用户名进行提取： 1cat list.txt | sed &apos;s/\\(.*\\)@\\(.*\\)/\\1/g&apos; &gt;&gt;user.list 分别对应生成密码，这里采用了linux下的makepassword工具包批量生成密码 1makepasswd --count=404 采用gitlab的命令行工具进行批量的用户创建 gitlab 提供了一个可以通过private token的方式进行命令行创建用户等操作，这样省去了手动创建的操作。 我们通过以下两个脚本进行用户的批量创建： 创建用户脚本 12345678#!/bin/bash#MAIL=$1USER=$1PASS=$2curl -H &quot;Content-Type:application/json&quot; http://IP/api/v3/users?private_token=XXXXXXX -d \\&quot;&#123; \\&quot;email\\&quot;:\\&quot;$1@IP\\&quot;,\\&quot;password\\&quot;:\\&quot;$2\\&quot;,\\&quot;name\\&quot;:\\&quot;$1\\&quot;,\\&quot;username\\&quot;:\\&quot;$1\\&quot;,\\&quot;confirm\\&quot;:\\&quot;false\\&quot; &#125;&quot; 批量创建脚本 12345678#!/bin/bashcat final.txt | while read name passworddo echo $name echo $password ./create-git-account.sh $name $passworddone Spark介绍SparkApache Spark是一个开源簇运算框架，最初是由加州大学柏克莱分校AMPLab所开发。相对于Hadoop的MapReduce会在运行完工作后将中介数据存放到磁盘中，Spark使用了存储器内运算技术，能在数据尚未写入硬盘时即在存储器内分析运算。Spark在存储器内运行程序的运算速度能做到比Hadoop MapReduce的运算速度快上100倍，即便是运行程序于硬盘时，Spark也能快上10倍速度。 Spark集群介绍本次比赛中OMNILab为参赛选手提供了强大的Spark集群： 2个控制节点，8个计算节点，1个客户端节点 共计256核和2TB物理内存可用于计算 使用方法 上传代码到git,参照模版来提交你的代码，代码准备完毕后创建release branch后台调度器会自动调度代码到Spark上运行 从release branch上拿到结果 搞定！","tags":[{"name":"SODA","slug":"SODA","permalink":"http://yoursite.com/tags/SODA/"}]}]